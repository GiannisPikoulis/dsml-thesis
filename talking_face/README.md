### Preparation
* Download MEAD dataset from [here](https://wywu.github.io/projects/MEAD/MEAD). Please correct all path variables correspondingly.
* Inside the `/data/LRS3_V_WER32.3` directory, place the corresponding `model.pth` and `model.json` files, that can be downloaded from [Model-Zoo](https://github.com/mpc001/Visual_Speech_Recognition_for_Multiple_Languages/tree/master#Model-Zoo). We recommend using the [LSR3 VSR model for multiple languages (32.3 WER)](https://drive.google.com/file/d/1yHd4QwC7K_9Ro2OM_hC7pKUT2URPvm_f/view).